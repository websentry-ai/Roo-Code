import type { ModelInfo } from "../model.js"

/**
 * Azure AI Foundry model metadata.
 *
 * NOTE:
 * - Azure AI Foundry uses *deployment names* at runtime, but Roo still needs underlying model
 *   capabilities (maxTokens/contextWindow/etc.) for validation and parameter shaping.
 * - This list is derived from https://models.dev/api.json (provider: "azure") and intentionally
 *   restricted to OpenAI/Azure OpenAI-style IDs (gpt-*, o*, codex-*).
 */
export const azureModels = {
	"codex-mini": {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: false,
		supportsPromptCache: true,
		inputPrice: 1.5,
		outputPrice: 6,
		cacheReadsPrice: 0.375,
		supportsTemperature: false,
		description:
			"Codex Mini: Cloud-based software engineering agent powered by codex-1, a version of o3 optimized for coding tasks",
	},
	"gpt-4": {
		maxTokens: 8_192,
		contextWindow: 8_192,
		supportsImages: false,
		supportsPromptCache: false,
		inputPrice: 60,
		outputPrice: 120,
		supportsTemperature: true,
		description: "GPT-4",
	},
	"gpt-4-32k": {
		maxTokens: 32_768,
		contextWindow: 32_768,
		supportsImages: false,
		supportsPromptCache: false,
		inputPrice: 60,
		outputPrice: 120,
		supportsTemperature: true,
		description: "GPT-4 32K",
	},
	"gpt-4-turbo": {
		maxTokens: 4_096,
		contextWindow: 128_000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 10,
		outputPrice: 30,
		supportsTemperature: true,
		description: "GPT-4 Turbo",
	},
	"gpt-4-turbo-vision": {
		maxTokens: 4_096,
		contextWindow: 128_000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 10,
		outputPrice: 30,
		supportsTemperature: true,
		description: "GPT-4 Turbo Vision",
	},
	"gpt-4.1": {
		maxTokens: 32_768,
		contextWindow: 1_047_576,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 2,
		outputPrice: 8,
		cacheReadsPrice: 0.5,
		supportsTemperature: true,
		description: "GPT-4.1",
	},
	"gpt-4.1-mini": {
		maxTokens: 32_768,
		contextWindow: 1_047_576,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 0.4,
		outputPrice: 1.6,
		cacheReadsPrice: 0.1,
		supportsTemperature: true,
		description: "GPT-4.1 mini",
	},
	"gpt-4.1-nano": {
		maxTokens: 32_768,
		contextWindow: 1_047_576,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 0.1,
		outputPrice: 0.4,
		cacheReadsPrice: 0.03,
		supportsTemperature: true,
		description: "GPT-4.1 nano",
	},
	"gpt-4o": {
		maxTokens: 16_384,
		contextWindow: 128_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 2.5,
		outputPrice: 10,
		cacheReadsPrice: 1.25,
		supportsTemperature: true,
		description: "GPT-4o",
	},
	"gpt-4o-mini": {
		maxTokens: 16_384,
		contextWindow: 128_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 0.15,
		outputPrice: 0.6,
		cacheReadsPrice: 0.08,
		supportsTemperature: true,
		description: "GPT-4o mini",
	},
	"gpt-5": {
		maxTokens: 128_000,
		contextWindow: 272_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: ["minimal", "low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 1.25,
		outputPrice: 10,
		cacheReadsPrice: 0.13,
		supportsVerbosity: true,
		supportsTemperature: false,
		description: "GPT-5: The best model for coding and agentic tasks across domains",
	},
	"gpt-5-codex": {
		maxTokens: 128_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: ["low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 1.25,
		outputPrice: 10,
		cacheReadsPrice: 0.13,
		supportsTemperature: false,
		description: "GPT-5-Codex: A version of GPT-5 optimized for agentic coding in Codex",
	},
	"gpt-5-mini": {
		maxTokens: 128_000,
		contextWindow: 272_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: ["minimal", "low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 0.25,
		outputPrice: 2,
		cacheReadsPrice: 0.03,
		supportsVerbosity: true,
		supportsTemperature: false,
		description: "GPT-5 Mini: A faster, more cost-efficient version of GPT-5 for well-defined tasks",
	},
	"gpt-5-nano": {
		maxTokens: 128_000,
		contextWindow: 272_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: ["minimal", "low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 0.05,
		outputPrice: 0.4,
		cacheReadsPrice: 0.01,
		supportsVerbosity: true,
		supportsTemperature: false,
		description: "GPT-5 Nano: Fastest, most cost-efficient version of GPT-5",
	},
	"gpt-5-pro": {
		maxTokens: 272_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: false,
		supportsReasoningEffort: ["minimal", "low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 15,
		outputPrice: 120,
		supportsVerbosity: true,
		supportsTemperature: false,
		description: "GPT-5 Pro",
	},
	"gpt-5.1": {
		maxTokens: 128_000,
		contextWindow: 272_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		supportsReasoningEffort: ["none", "low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 1.25,
		outputPrice: 10,
		cacheReadsPrice: 0.125,
		supportsVerbosity: true,
		supportsTemperature: false,
		description: "GPT-5.1: The best model for coding and agentic tasks across domains",
	},
	"gpt-5.1-chat": {
		maxTokens: 16_384,
		contextWindow: 128_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		inputPrice: 1.25,
		outputPrice: 10,
		cacheReadsPrice: 0.125,
		supportsTemperature: false,
		description: "GPT-5.1 Chat: Optimized for conversational AI and chat use cases",
	},
	"gpt-5.1-codex": {
		maxTokens: 128_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		supportsReasoningEffort: ["low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 1.25,
		outputPrice: 10,
		cacheReadsPrice: 0.125,
		supportsTemperature: false,
		description: "GPT-5.1 Codex: A version of GPT-5.1 optimized for agentic coding in Codex",
	},
	"gpt-5.1-codex-max": {
		maxTokens: 128_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		supportsReasoningEffort: ["low", "medium", "high", "xhigh"],
		reasoningEffort: "medium",
		inputPrice: 1.25,
		outputPrice: 10,
		cacheReadsPrice: 0.125,
		supportsTemperature: false,
		description:
			"GPT-5.1 Codex Max: Our most intelligent coding model optimized for long-horizon, agentic coding tasks",
	},
	"gpt-5.1-codex-mini": {
		maxTokens: 128_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		supportsReasoningEffort: ["low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 0.25,
		outputPrice: 2,
		cacheReadsPrice: 0.025,
		supportsTemperature: false,
		description: "GPT-5.1 Codex mini: A version of GPT-5.1 optimized for agentic coding in Codex",
	},
	"gpt-5.2": {
		maxTokens: 128_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		supportsReasoningEffort: ["none", "low", "medium", "high", "xhigh"],
		reasoningEffort: "medium",
		inputPrice: 1.75,
		outputPrice: 14,
		cacheReadsPrice: 0.125,
		supportsVerbosity: true,
		supportsTemperature: false,
		description: "GPT-5.2: Our flagship model for coding and agentic tasks across industries",
	},
	"gpt-5.2-chat": {
		maxTokens: 16_384,
		contextWindow: 128_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 1.75,
		outputPrice: 14,
		cacheReadsPrice: 0.175,
		supportsTemperature: false,
		description: "GPT-5.2 Chat: Optimized for conversational AI and chat use cases",
	},
	"gpt-5.2-codex": {
		maxTokens: 128_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		supportsReasoningEffort: ["low", "medium", "high", "xhigh"],
		reasoningEffort: "medium",
		inputPrice: 1.75,
		outputPrice: 14,
		cacheReadsPrice: 0.175,
		supportsTemperature: false,
		description:
			"GPT-5.2 Codex: Our most intelligent coding model optimized for long-horizon, agentic coding tasks",
	},
	o1: {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 15,
		outputPrice: 60,
		cacheReadsPrice: 7.5,
		supportsTemperature: false,
		description: "o1",
	},
	"o1-mini": {
		maxTokens: 65_536,
		contextWindow: 128_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 1.1,
		outputPrice: 4.4,
		cacheReadsPrice: 0.55,
		supportsTemperature: false,
		description: "o1-mini",
	},
	"o1-preview": {
		maxTokens: 32_768,
		contextWindow: 128_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 16.5,
		outputPrice: 66,
		cacheReadsPrice: 8.25,
		supportsTemperature: false,
		description: "o1-preview",
	},
	o3: {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: ["low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 2,
		outputPrice: 8,
		cacheReadsPrice: 0.5,
		supportsTemperature: false,
		description: "o3",
	},
	"o3-mini": {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: false,
		supportsPromptCache: true,
		supportsReasoningEffort: ["low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 1.1,
		outputPrice: 4.4,
		cacheReadsPrice: 0.55,
		supportsTemperature: false,
		description: "o3-mini",
	},
	"o4-mini": {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: ["low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 1.1,
		outputPrice: 4.4,
		cacheReadsPrice: 0.28,
		supportsTemperature: false,
		description: "o4-mini",
	},
} as const satisfies Record<string, ModelInfo>

export type AzureModelId = keyof typeof azureModels

export const azureDefaultModelId: AzureModelId = "gpt-4o"

export const azureDefaultModelInfo: ModelInfo = azureModels[azureDefaultModelId]
